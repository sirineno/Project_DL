{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import requests\n",
    "import ssl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix SSL issue for downloading ImageNet labels\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Detect available device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define paths to dataset\n",
    "\n",
    "# train_images_dir = \"/Users/selmaakarsu/Desktop/MBB3/Deep Learning/semester_project/salicon_data/train\"\n",
    "# train_annotations_file = \"/Users/selmaakarsu/Desktop/MBB3/Deep Learning/semester_project/salicon_data/fixations_train2014.json\"\n",
    "\n",
    "train_images_dir = \"/Users/nouira/Desktop/deeplearning/project/train\"\n",
    "train_annotations_file = \"/Users/nouira/Desktop/deeplearning/project/fixations_train2014.json\"\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaliconDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_file, transform=None, max_samples=100):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "        self.image_ids = [img['id'] for img in self.annotations['images'][:max_samples]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_data = next(img for img in self.annotations['images'] if img['id'] == img_id)\n",
    "        img_path = os.path.join(self.image_dir, img_data['file_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        ann = next(ann for ann in self.annotations['annotations'] if ann['image_id'] == img_id)\n",
    "        fixations = ann['fixations']\n",
    "        heatmap = torch.zeros((img_data['height'], img_data['width']))\n",
    "        for row, col in fixations:\n",
    "            heatmap[row - 1, col - 1] += 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SaliconDataset(train_images_dir, train_annotations_file, transform=transform, max_samples=50)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Define preprocessing for feature extraction\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained ResNet model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove final FC layer\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataset, batch_size=2, device=device):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "            images = images.to(device)  # Since images are already Tensors\n",
    "            batch_features = model(images).view(images.size(0), -1)\n",
    "            features.append(batch_features.cpu())\n",
    "    return torch.cat(features, dim=0)\n",
    "\n",
    "\n",
    "# Extract features\n",
    "features = extract_features(train_dataset)\n",
    "torch.save(features, \"train_features.pt\")\n",
    "print(f\"Extracted features shape: {features.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
